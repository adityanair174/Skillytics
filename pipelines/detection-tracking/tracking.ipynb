{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "155166a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a20eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_VIDEO_DIRECTORY = Path(\"./videos/Game-1/\")\n",
    "SOURCE_VIDEO_PATH = SOURCE_VIDEO_DIRECTORY / \"cam0_2025-11-14_19-48-45.mp4\"\n",
    "\n",
    "TARGET_VIDEO_DIRECTORY = Path(\"./output_videos/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48760a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/27/25 19:57:32] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> Your inference package version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.63</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> is out of date! Please upgrade to <a href=\"file:///home/kinal/Desktop/opensource/sports-tracker-v1/football_works/.venv/lib/python3.12/site-packages/inference/core/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/kinal/Desktop/opensource/sports-tracker-v1/football_works/.venv/lib/python3.12/site-packages/inference/core/__init__.py#41\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.63</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of inference for the latest features and bug fixes by    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         running `pip install --upgrade inference`.                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/27/25 19:57:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m Your inference package version \u001b[1;36m0.63\u001b[0m.\u001b[1;36m1\u001b[0m is out of date! Please upgrade to \u001b]8;id=41515;file:///home/kinal/Desktop/opensource/sports-tracker-v1/football_works/.venv/lib/python3.12/site-packages/inference/core/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=321829;file:///home/kinal/Desktop/opensource/sports-tracker-v1/football_works/.venv/lib/python3.12/site-packages/inference/core/__init__.py#41\u001b\\\u001b[2m41\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         version \u001b[1;36m0.63\u001b[0m.\u001b[1;36m2\u001b[0m of inference for the latest features and bug fixes by    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         running `pip install --upgrade inference`.                              \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelDependencyMissing: Your `inference` configuration does not support SAM model. Use pip install 'inference[sam]' to install missing requirements.To suppress this warning, set CORE_MODEL_SAM_ENABLED to False.\n",
      "ModelDependencyMissing: Your `inference` configuration does not support SAM3 model. Install SAM3 dependencies and set CORE_MODEL_SAM3_ENABLED to True.\n",
      "ModelDependencyMissing: Your `inference` configuration does not support Gaze Detection model. Use pip install 'inference[gaze]' to install missing requirements.To suppress this warning, set CORE_MODEL_GAZE_ENABLED to False.\n",
      "FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "ModelDependencyMissing: Your `inference` configuration does not support YoloWorld model. Use pip install 'inference[yolo-world]' to install missing requirements.To suppress this warning, set CORE_MODEL_YOLO_WORLD_ENABLED to False.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "from typing import Dict, List, Optional, Union, Iterable, Tuple\n",
    "from operator import itemgetter\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import supervision as sv\n",
    "from rfdetr import RFDETRBase\n",
    "\n",
    "from inference import get_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0b94d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Specified provider 'CoreMLExecutionProvider' is not in available provider names.Available providers: 'TensorrtExecutionProvider, CUDAExecutionProvider, CPUExecutionProvider'\n"
     ]
    }
   ],
   "source": [
    "# model = RFDETRBase()\n",
    "box_annotator = sv.BoxAnnotator(thickness=2)\n",
    "label_annotator = sv.LabelAnnotator(text_color=sv.Color.BLACK)\n",
    "\n",
    "infer_model = get_model(\"rfdetr-base\", device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de319734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam2.build_sam import build_sam2_camera_predictor\n",
    "\n",
    "SAM2_HOME = Path(\"../segment-anything-2-real-time\")\n",
    "SAM2_CHECKPOINT = SAM2_HOME / \"checkpoints/sam2.1_hiera_tiny.pt\"\n",
    "SAM2_CONFIG = \"configs/sam2.1/sam2.1_hiera_t.yaml\"\n",
    "\n",
    "predictor = build_sam2_camera_predictor(str(SAM2_CONFIG), str(SAM2_CHECKPOINT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4e69c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SAM2Tracker:\n",
    "    def __init__(self, predictor) -> None:\n",
    "        self.predictor = predictor\n",
    "        self._prompted = False\n",
    "\n",
    "    def prompt_first_frame(self, frame: np.ndarray, detections: sv.Detections) -> None:\n",
    "        if len(detections) == 0:\n",
    "            raise ValueError(\"detections must contain at least one box\")\n",
    "\n",
    "        if detections.tracker_id is None:\n",
    "            detections.tracker_id = list(range(1, len(detections) + 1))\n",
    "\n",
    "        with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            self.predictor.load_first_frame(frame)\n",
    "            for xyxy, obj_id in zip(detections.xyxy, detections.tracker_id):\n",
    "                bbox = np.asarray([xyxy], dtype=np.float32)\n",
    "                self.predictor.add_new_prompt(\n",
    "                    frame_idx=0,\n",
    "                    obj_id=int(obj_id),\n",
    "                    bbox=bbox,\n",
    "                )\n",
    "\n",
    "        self._prompted = True\n",
    "\n",
    "    def propagate(self, frame: np.ndarray) -> sv.Detections:\n",
    "        if not self._prompted:\n",
    "            raise RuntimeError(\"Call prompt_first_frame before propagate\")\n",
    "\n",
    "        with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            tracker_ids, mask_logits = self.predictor.track(frame)\n",
    "\n",
    "        tracker_ids = np.asarray(tracker_ids, dtype=np.int32)\n",
    "        masks = (mask_logits > 0.0).cpu().numpy()\n",
    "        masks = np.squeeze(masks).astype(bool)\n",
    "\n",
    "        if masks.ndim == 2:\n",
    "            masks = masks[None, ...]\n",
    "\n",
    "        masks = np.array([\n",
    "            sv.filter_segments_by_distance(mask, relative_distance=0.03, mode=\"edge\")\n",
    "            for mask in masks\n",
    "        ])\n",
    "\n",
    "        xyxy = sv.mask_to_xyxy(masks=masks)\n",
    "        detections = sv.Detections(xyxy=xyxy, mask=masks, tracker_id=tracker_ids)\n",
    "        return detections\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self._prompted = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "569fde82",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VIDEO_PATH = TARGET_VIDEO_DIRECTORY / f\"{SOURCE_VIDEO_PATH.stem}-mask{SOURCE_VIDEO_PATH.suffix}\"\n",
    "TARGET_VIDEO_COMPRESSED_PATH = TARGET_VIDEO_DIRECTORY / f\"{TARGET_VIDEO_PATH.stem}-compressed{TARGET_VIDEO_PATH.suffix}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "741f50d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrain weights\n"
     ]
    }
   ],
   "source": [
    "mask_annotator = sv.MaskAnnotator(\n",
    "    color_lookup=sv.ColorLookup.TRACK,\n",
    "    opacity=0.5)\n",
    "box_annotator = sv.BoxAnnotator(\n",
    "    color_lookup=sv.ColorLookup.TRACK,\n",
    "    thickness=2\n",
    ")\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "model = RFDETRBase()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a64343f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rfdetr.detr:Model is not optimized for inference. Latency may be higher than expected. You can optimize the model for inference by calling model.optimize_for_inference().\n",
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)\n",
      "UserWarning: cannot import name '_C' from 'sam2' (/home/kinal/Desktop/opensource/sports-tracker-v1/segment-anything-2-real-time/sam2/__init__.py)\n",
      "\n",
      "Skipping the post-processing step due to the error above. You can still use SAM 2 and it's OK to ignore the error above, although some post-processing functionality may be limited (which doesn't affect the results in most cases; see https://github.com/facebookresearch/sam2/blob/main/INSTALL.md).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf134b2059134f7db05f9f3ad57c847b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing video:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: cannot import name '_C' from 'sam2' (/home/kinal/Desktop/opensource/sports-tracker-v1/segment-anything-2-real-time/sam2/__init__.py)\n",
      "\n",
      "Skipping the post-processing step due to the error above. You can still use SAM 2 and it's OK to ignore the error above, although some post-processing functionality may be limited (which doesn't affect the results in most cases; see https://github.com/facebookresearch/sam2/blob/main/INSTALL.md).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m[vost#0:0 @ 0x55fb5348a740] \u001b[0m\u001b[4;31mUnknown encoder 'libx264'\n",
      "\u001b[0m\u001b[1;35m[vost#0:0 @ 0x55fb5348a740] \u001b[0m\u001b[4;31mError selecting an encoder\n",
      "\u001b[0m\u001b[1;31mError opening output file output_videos/cam0_2025-11-14_19-48-45-mask-compressed.mp4.\n",
      "\u001b[0m\u001b[4;31mError opening output files: Encoder not found\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "detections = model.predict(frame)\n",
    "\n",
    "def filter_detections(detections: sv.Detections) -> sv.Detections:\n",
    "    # only keep person human and balls\n",
    "    detections = detections[np.isin(detections.class_id, (1, 37))]\n",
    "    return detections\n",
    "\n",
    "detections = filter_detections(detections)\n",
    "\n",
    "# we prompt SAM2 using RF-DETR model detections\n",
    "tracker = SAM2Tracker(predictor)\n",
    "tracker.prompt_first_frame(frame, detections)\n",
    "\n",
    "# we propagate tacks across all video frames\n",
    "\n",
    "def callback(frame: np.ndarray, index: int) -> np.ndarray:\n",
    "    detections = tracker.propagate(frame)\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = mask_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "    annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "    return annotated_frame\n",
    "\n",
    "sv.process_video(\n",
    "    source_path=SOURCE_VIDEO_PATH,\n",
    "    target_path=TARGET_VIDEO_PATH,\n",
    "    callback=callback,\n",
    "    max_frames = 3000,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "!ffmpeg -y -loglevel error -i {TARGET_VIDEO_PATH} -vcodec libx264 -crf 28 {TARGET_VIDEO_COMPRESSED_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020bd837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "football_works",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
